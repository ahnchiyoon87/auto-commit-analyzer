#!/usr/bin/env python3
# -*- coding: utf-8 -*-

import os, json, textwrap, datetime as dt
from typing import List, Optional, Dict, Any
from dateutil import tz
from tenacity import retry, wait_random_exponential, stop_after_attempt
from github import Github
from openai import OpenAI
from dotenv import load_dotenv

# ======================================
# ğŸ”§ 1. í™˜ê²½ì„¤ì •
# ======================================
# .env íŒŒì¼ì—ì„œ í™˜ê²½ë³€ìˆ˜ ë¡œë“œ (ì—†ìœ¼ë©´ ë¬´ì‹œ)
load_dotenv()

# --- [A] í•˜ë“œì½”ë”© ì„¤ì • (ì›í•˜ë©´ ì´ ë¸”ë¡ë§Œ ìˆ˜ì •) ---
DEFAULT_REPOS = [
    "msa-ez/legacy-modernizer-frontend",
    "uengine-oss/legacy-modernizer-backend", 
    "ahnchiyoon87/Antlr-Server"
]
MY_GITHUB_LOGIN = os.getenv("MY_GITHUB_LOGIN", "your-github-id")     # GitHub ë¡œê·¸ì¸ ì•„ì´ë””
MY_GITHUB_EMAIL = os.getenv("MY_GITHUB_EMAIL", "you@company.com")     # ì»¤ë°‹ ì´ë©”ì¼
OPENAI_MODEL = os.getenv("OPENAI_MODEL", "gpt-4o-mini")               # OpenAI ëª¨ë¸
BRANCH = os.getenv("BRANCH", "main")                                  # ë¶„ì„í•  ë¸Œëœì¹˜
OUT_DIR = os.getenv("OUT_DIR", "./reports")                           # ê²°ê³¼ ì €ì¥ í´ë”
os.makedirs(OUT_DIR, exist_ok=True)

# --- [B] í† í° ê´€ë¦¬ ---
GITHUB_TOKEN = os.getenv("GITHUB_TOKEN", "ghp_...")                   # GitHub Personal Access Token
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY", "sk-...")                # OpenAI API Key

if not GITHUB_TOKEN or not OPENAI_API_KEY:
    raise RuntimeError("âŒ GITHUB_TOKEN ë˜ëŠ” OPENAI_API_KEYê°€ ëˆ„ë½ë˜ì—ˆìŠµë‹ˆë‹¤. .envì— ì„¤ì •í•˜ì„¸ìš”.")

# ======================================
# ğŸ“¦ 2. ë°ì´í„° ëª¨ë¸ ì •ì˜ (Pydantic ì—†ì´)
# ======================================
class FileFinding:
    def __init__(self, file_path: str, change_type: str, summary: str, risk_level: str, 
                 breaking_changes: List[str] = None, test_impact: List[str] = None, 
                 migration_notes: List[str] = None, owner_guess: Optional[str] = None):
        self.file_path = file_path
        self.change_type = change_type
        self.summary = summary
        self.risk_level = risk_level
        self.breaking_changes = breaking_changes or []
        self.test_impact = test_impact or []
        self.migration_notes = migration_notes or []
        self.owner_guess = owner_guess
    
    def to_dict(self) -> Dict[str, Any]:
        return {
            "file_path": self.file_path,
            "change_type": self.change_type,
            "summary": self.summary,
            "risk_level": self.risk_level,
            "breaking_changes": self.breaking_changes,
            "test_impact": self.test_impact,
            "migration_notes": self.migration_notes,
            "owner_guess": self.owner_guess
        }

class CommitFinding:
    def __init__(self, repo: str, sha: str, author: Optional[str], author_login: Optional[str], 
                 author_email: Optional[str], date_kst: str, title: str, files: List[FileFinding],
                 overall_summary: str, overall_risk: str):
        self.repo = repo
        self.sha = sha
        self.author = author
        self.author_login = author_login
        self.author_email = author_email
        self.date_kst = date_kst
        self.title = title
        self.files = files
        self.overall_summary = overall_summary
        self.overall_risk = overall_risk

class ReportModel:
    def __init__(self, generated_at: str, model: str, note_date_kst: str, repos: List[str], 
                 branch: str, author_filter: dict, commits: List[CommitFinding]):
        self.generated_at = generated_at
        self.model = model
        self.note_date_kst = note_date_kst
        self.repos = repos
        self.branch = branch
        self.author_filter = author_filter
        self.commits = commits
    
    def to_dict(self) -> Dict[str, Any]:
        return {
            "generated_at": self.generated_at,
            "model": self.model,
            "note_date_kst": self.note_date_kst,
            "repos": self.repos,
            "branch": self.branch,
            "author_filter": self.author_filter,
            "commits": [
                {
                    "repo": c.repo,
                    "sha": c.sha,
                    "author": c.author,
                    "author_login": c.author_login,
                    "author_email": c.author_email,
                    "date_kst": c.date_kst,
                    "title": c.title,
                    "files": [f.to_dict() for f in c.files],
                    "overall_summary": c.overall_summary,
                    "overall_risk": c.overall_risk
                } for c in self.commits
            ]
        }

# ======================================
# â° 3. ë‚ ì§œ ê³„ì‚° (ì˜¤ëŠ˜ ë‚ ì§œ ìë™)
# ======================================
def get_today_kst_bounds():
    kst = tz.gettz("Asia/Seoul")
    now_kst = dt.datetime.now(tz=kst)
    note_date = now_kst.strftime("%Y-%m-%d")
    start_kst = now_kst.replace(hour=0, minute=0, second=0, microsecond=0)
    end_kst = start_kst + dt.timedelta(days=1)
    return note_date, start_kst.astimezone(tz.UTC), end_kst.astimezone(tz.UTC)

# ======================================
# ğŸ¤– 4. OpenAI & GitHub í´ë¼ì´ì–¸íŠ¸
# ======================================
gh = Github(GITHUB_TOKEN, per_page=100)
oai = OpenAI(api_key=OPENAI_API_KEY)

SYSTEM_PROMPT = (
    "ë‹¹ì‹ ì€ ë§¤ìš° ê²½í—˜ ë§ì€ ì‹œë‹ˆì–´ ì½”ë“œ ë¦¬ë·°ì–´ì´ì ê¸°ìˆ  ë¬¸ì„œ ì‘ì„±ìì…ë‹ˆë‹¤. íŒŒì¼ ë³€ê²½ì‚¬í•­ì„ ë§¤ìš° ìƒì„¸í•˜ê³  í¬ê´„ì ìœ¼ë¡œ ë¶„ì„í•˜ì—¬ ì—°êµ¬ë…¸íŠ¸ ìˆ˜ì¤€ì˜ ìì„¸í•œ ì„¤ëª…ì„ ì œê³µí•˜ì„¸ìš”. "
    "JSON í˜•ì‹ìœ¼ë¡œ ì‘ë‹µí•˜ë˜: file_path, change_type, summary (ìµœì†Œ 300ë‹¨ì–´ ì´ìƒ), risk_level (low/medium/high), "
    "breaking_changes (ë°°ì—´), test_impact (ë°°ì—´), migration_notes (ë°°ì—´). "
    "í•œê¸€ë¡œ ë§¤ìš° ìƒì„¸í•˜ê²Œ ë‹¤ìŒì„ ëª¨ë‘ í¬í•¨í•˜ì—¬ ì„¤ëª…í•˜ì„¸ìš”: "
    "1) êµ¬ì²´ì ì¸ ì½”ë“œ ë³€ê²½ ë‚´ìš©ê³¼ ê¸°ìˆ ì  ì„¸ë¶€ì‚¬í•­, "
    "2) ë³€ê²½ì˜ ë°°ê²½ê³¼ ë¹„ì¦ˆë‹ˆìŠ¤ì /ê¸°ìˆ ì  í•„ìš”ì„±, "
    "3) í•´ê²°í•˜ë ¤ëŠ” ë¬¸ì œì™€ ê¸°ì¡´ ì´ìŠˆ, "
    "4) êµ¬í˜„ ë°©ì‹ê³¼ ì•„í‚¤í…ì²˜ì  ê³ ë ¤ì‚¬í•­, "
    "5) ì„±ëŠ¥, ë³´ì•ˆ, ìœ ì§€ë³´ìˆ˜ì„±ì— ë¯¸ì¹˜ëŠ” ì˜í–¥, "
    "6) ë‹¤ë¥¸ ëª¨ë“ˆì´ë‚˜ ì‹œìŠ¤í…œê³¼ì˜ ì—°ê´€ì„±, "
    "7) í–¥í›„ í™•ì¥ì„±ê³¼ ê°œì„  ë°©í–¥, "
    "8) ê°œë°œìë‚˜ íŒ€ì—ê²Œ ë¯¸ì¹˜ëŠ” ì˜í–¥, "
    "9) ì ì¬ì  ìœ„í—˜ê³¼ ì£¼ì˜ì‚¬í•­, "
    "10) í…ŒìŠ¤íŠ¸ ì „ëµê³¼ ê²€ì¦ ë°©ë²•. "
    "ì—°êµ¬ë…¸íŠ¸ ìˆ˜ì¤€ì˜ ê¹Šì´ì™€ ìƒì„¸í•¨ìœ¼ë¡œ ì‘ì„±í•˜ì„¸ìš”."
)

# ======================================
# ğŸ§  5. LLM í˜¸ì¶œ
# ======================================
@retry(wait=wait_random_exponential(min=1, max=20), stop=stop_after_attempt(4))
def analyze_file(file_path: str, change_type: str, patch: str) -> FileFinding:
    resp = oai.chat.completions.create(
        model=OPENAI_MODEL,
        response_format={"type":"json_object"},
        messages=[
            {"role":"system", "content": SYSTEM_PROMPT},
            {"role":"user", "content": f"file_path: {file_path}\nchange_type: {change_type}\n\nDIFF:\n{patch or ''}"}
        ]
    ).choices[0].message.content
    try:
        data = json.loads(resp)
        return FileFinding(
            file_path=data.get("file_path", file_path),
            change_type=data.get("change_type", change_type),
            summary=data.get("summary", "LLM parsing failed"),
            risk_level=data.get("risk_level", "medium"),
            breaking_changes=data.get("breaking_changes", []),
            test_impact=data.get("test_impact", []),
            migration_notes=data.get("migration_notes", []),
            owner_guess=data.get("owner_guess")
        )
    except Exception:
        return FileFinding(file_path=file_path, change_type=change_type, summary="LLM parsing failed", risk_level="medium")

@retry(wait=wait_random_exponential(min=1, max=20), stop=stop_after_attempt(4))
def summarize_commit(files: List[FileFinding], meta: dict) -> CommitFinding:
    resp = oai.chat.completions.create(
        model=OPENAI_MODEL,
        response_format={"type":"json_object"},
        messages=[
            {"role":"system","content":"ì»¤ë°‹ì˜ ì „ì²´ì ì¸ ì‘ì—… ë‚´ìš©ì„ ì—°êµ¬ë…¸íŠ¸ ìˆ˜ì¤€ìœ¼ë¡œ ë§¤ìš° ìƒì„¸í•˜ê³  í¬ê´„ì ìœ¼ë¡œ í•œê¸€ë¡œ ì„œìˆ í•˜ì„¸ìš”. ìµœì†Œ 1000ë‹¨ì–´ ì´ìƒìœ¼ë¡œ ë‹¤ìŒì„ ëª¨ë‘ í¬í•¨í•˜ì—¬ ì„¤ëª…í•˜ì„¸ìš”: 1) ìˆ˜í–‰í•œ ì‘ì—…ì˜ êµ¬ì²´ì  ë‚´ìš©ê³¼ ê¸°ìˆ ì  ì„¸ë¶€ì‚¬í•­, 2) ì‘ì—…ì˜ ë°°ê²½ê³¼ ë¹„ì¦ˆë‹ˆìŠ¤ì /ê¸°ìˆ ì  í•„ìš”ì„±, 3) í•´ê²°í•˜ë ¤ëŠ” ë¬¸ì œì™€ ê¸°ì¡´ ì´ìŠˆì˜ ë§¥ë½, 4) ì„ íƒí•œ ê¸°ìˆ ì  ì ‘ê·¼ ë°©ì‹ê³¼ êµ¬í˜„ ì „ëµ, 5) ì½”ë“œ ì•„í‚¤í…ì²˜ì˜ ë³€í™”ì™€ ì„¤ê³„ ê°œì„ ì , 6) ì„±ëŠ¥, ë³´ì•ˆ, í™•ì¥ì„±, ìœ ì§€ë³´ìˆ˜ì„±ì— ë¯¸ì¹˜ëŠ” ì˜í–¥, 7) ë‹¤ë¥¸ ì‹œìŠ¤í…œì´ë‚˜ ëª¨ë“ˆê³¼ì˜ ì—°ê´€ì„±ê³¼ ì˜ì¡´ì„±, 8) íŒ€ ê°œë°œ í”„ë¡œì„¸ìŠ¤ì™€ í˜‘ì—…ì— ë¯¸ì¹˜ëŠ” ì˜í–¥, 9) í–¥í›„ ê°œë°œ ë°©í–¥ê³¼ í™•ì¥ ê°€ëŠ¥ì„±, 10) ì ì¬ì  ìœ„í—˜ê³¼ ëŒ€ì‘ ë°©ì•ˆ, 11) í…ŒìŠ¤íŠ¸ ì „ëµê³¼ í’ˆì§ˆ ë³´ì¦ ë°©ë²•, 12) ë¬¸ì„œí™”ì™€ ì§€ì‹ ê³µìœ  ì¸¡ë©´, 13) ë¹„ìš©ê³¼ ë¦¬ì†ŒìŠ¤ì— ë¯¸ì¹˜ëŠ” ì˜í–¥, 14) ì‚¬ìš©ìë‚˜ ê³ ê°ì—ê²Œ ë¯¸ì¹˜ëŠ” ì˜í–¥. ê° íŒŒì¼ì˜ ë³€ê²½ì‚¬í•­ì„ ì¢…í•©í•˜ì—¬ í•˜ë‚˜ì˜ ì¼ê´€ë˜ê³  ì™„ì „í•œ ì‘ì—… ìŠ¤í† ë¦¬ë¡œ ì„¤ëª…í•˜ì„¸ìš”. ì—°êµ¬ë…¸íŠ¸ì˜ ê¹Šì´ì™€ ì „ë¬¸ì„±ì„ ìœ ì§€í•˜ì„¸ìš”."},
            {"role":"user","content":json.dumps({"meta":meta,"files":[f.to_dict() for f in files]}, ensure_ascii=False)}
        ]
    ).choices[0].message.content
    data = json.loads(resp)
    return CommitFinding(
        repo=meta["repo"], 
        sha=meta["sha"], 
        author=meta.get("author"),
        author_login=meta.get("author_login"), 
        author_email=meta.get("author_email"),
        date_kst=meta["date_kst"], 
        title=meta["title"], 
        files=files,
        overall_summary=data.get("overall_summary",""), 
        overall_risk=data.get("overall_risk","medium")
    )

# ======================================
# ğŸ” 6. GitHub ì»¤ë°‹ í•„í„°
# ======================================
def commit_is_mine(commit) -> bool:
    login = getattr(commit.author, "login", None)
    email = getattr(commit.commit.author, "email", None)
    return (
        (login and login.lower() == MY_GITHUB_LOGIN.lower()) or
        (email and email.lower() == MY_GITHUB_EMAIL.lower())
    )

# ======================================
# ğŸ§¾ 7. ê²°ê³¼ ì¶œë ¥
# ======================================
def render_md(report: ReportModel) -> str:
    lines = [
        f"# ğŸ§  ì—°êµ¬ë…¸íŠ¸ â€” {report.note_date_kst} (KST)",
        "",
        f"- ìƒì„±ì‹œê°(UTC): {report.generated_at}",
        f"- ëª¨ë¸: `{report.model}`",
        f"- ë¦¬í¬ì§€í† ë¦¬: {', '.join(report.repos)}",
        f"- ë¸Œëœì¹˜: {report.branch}",
        f"- ì‘ì„±ì: {report.author_filter}",
        ""
    ]
    if not report.commits:
        lines.append("> ì˜¤ëŠ˜ì€ ë³¸ì¸ ì»¤ë°‹ì´ ì—†ìŠµë‹ˆë‹¤.")
        return "\n".join(lines)

    current_repo = None
    for c in report.commits:
        if c.repo != current_repo:
            current_repo = c.repo
            lines.append(f"## ğŸ“¦ {current_repo}\n")
        lines.append(f"### ğŸ”– {c.sha[:7]} â€” {c.title}")
        lines.append(f"- Date: {c.date_kst}")
        lines.append(f"- Risk: **{c.overall_risk}**")
        lines.append(f"- Repository: {c.repo}")
        lines.append(f"- Commit Link: https://github.com/{c.repo}/commit/{c.sha}")
        lines.append("")
        lines.append("## ğŸ“ ì‘ì—… ë‚´ìš© ì¢…í•© ë¶„ì„")
        lines.append("")
        lines.append("### ğŸ¯ ì‘ì—… ê°œìš”")
        lines.append("")
        lines.append("> " + (c.overall_summary or "(ìš”ì•½ ì—†ìŒ)").replace("\n", "\n> "))
        lines.append("")
        lines.append("## ğŸ“ íŒŒì¼ë³„ ìƒì„¸ ê¸°ìˆ  ë¶„ì„")
        lines.append("")
        for f in c.files:
            lines.append(f"### ğŸ“„ `{f.file_path}` ({f.change_type})")
            lines.append(f"**ìœ„í—˜ë„:** {f.risk_level}")
            lines.append("")
            lines.append("#### ğŸ” ê¸°ìˆ ì  ë³€ê²½ ë‚´ìš©")
            lines.append("")
            lines.append(f"{f.summary}")
            lines.append("")
            if f.breaking_changes:
                lines.append("#### âš ï¸ ì£¼ìš” ë³€ê²½ì‚¬í•­ ë° í˜¸í™˜ì„± ì˜í–¥")
                lines.append("")
                for change in f.breaking_changes:
                    lines.append(f"- {change}")
                lines.append("")
            if f.test_impact:
                lines.append("#### ğŸ§ª í…ŒìŠ¤íŠ¸ ì „ëµ ë° ì˜í–¥ ë¶„ì„")
                lines.append("")
                for impact in f.test_impact:
                    lines.append(f"- {impact}")
                lines.append("")
            if f.migration_notes:
                lines.append("#### ğŸ”„ ë§ˆì´ê·¸ë ˆì´ì…˜ ê°€ì´ë“œ ë° ì£¼ì˜ì‚¬í•­")
                lines.append("")
                for note in f.migration_notes:
                    lines.append(f"- {note}")
                lines.append("")
            lines.append("---")
            lines.append("")
    return "\n".join(lines)

# ======================================
# ğŸš€ 8. ë©”ì¸ ì‹¤í–‰
# ======================================
def main():
    note_date, since_utc, until_utc = get_today_kst_bounds()
    print(f"[INFO] Analyzing commits for {note_date} (KST)...")
    print(f"[INFO] Time range: {since_utc} ~ {until_utc} (UTC)")
    print(f"[INFO] Target repositories: {DEFAULT_REPOS}")
    print(f"[INFO] Branch: {BRANCH}")
    print(f"[INFO] Author filter: {MY_GITHUB_LOGIN} / {MY_GITHUB_EMAIL}")
    print("=" * 60)

    commits_all: List[CommitFinding] = []

    for repo_full in DEFAULT_REPOS:
        print(f"\n[REPO] Processing repository: {repo_full}")
        try:
            repo = gh.get_repo(repo_full)
            print(f"[REPO] âœ… Successfully connected to {repo_full}")
            
            commits = repo.get_commits(sha=BRANCH, since=since_utc, until=until_utc)
            commit_list = list(commits)
            print(f"[REPO] ğŸ“Š Found {len(commit_list)} total commits in time range")
            
            my_commits = []
            for i, c in enumerate(commit_list):
                if not commit_is_mine(c):
                    continue
                
                sha = c.sha
                print(f"[COMMIT] ğŸ” Processing commit {sha[:7]} ({i+1}/{len(commit_list)})")
                
                co = repo.get_commit(sha)
                title = co.commit.message.splitlines()[0].strip()
                author_name = co.commit.author.name if co.commit.author else None
                author_login = co.author.login if co.author else None
                author_email = co.commit.author.email if co.commit.author else None
                authored_dt = co.commit.author.date.replace(tzinfo=tz.UTC).astimezone(tz.gettz("Asia/Seoul"))
                date_kst_str = authored_dt.strftime("%Y-%m-%d %H:%M:%S %Z")
                
                print(f"[COMMIT] ğŸ“ Title: {title}")
                print(f"[COMMIT] ğŸ‘¤ Author: {author_name} ({author_email})")
                print(f"[COMMIT] ğŸ“… Date: {date_kst_str}")

                # íŒŒì¼ë³„ ë¶„ì„ (READMEë§Œ ì œì™¸, íŒŒì¼ ì œí•œ ì—†ìŒ)
                important_files = [f for f in co.files if 'readme' not in f.filename.lower()]
                files_to_analyze = important_files
                print(f"[COMMIT] ğŸ“ Analyzing {len(files_to_analyze)} files (out of {len(co.files)} total) - README excluded")
                
                # ì²˜ë¦¬í•  íŒŒì¼ì´ ì—†ìœ¼ë©´ ê±´ë„ˆë›°ê¸°
                if len(files_to_analyze) == 0:
                    print(f"[COMMIT] â­ï¸  Skipping commit (no files to analyze)")
                    continue
                
                file_findings = []
                for j, f in enumerate(files_to_analyze):
                    print(f"[FILE] ğŸ” Analyzing file {j+1}/{len(files_to_analyze)}: {f.filename} ({f.status})")
                    patch = getattr(f, "patch", None)
                    if not patch:
                        print(f"[FILE] âš ï¸  No patch available for {f.filename} (binary or no diff)")
                        file_findings.append(FileFinding(file_path=f.filename, change_type=f.status, summary="Binary or no diff", risk_level="medium"))
                    else:
                        print(f"[FILE] ğŸ¤– Sending to LLM for analysis...")
                        file_findings.append(analyze_file(f.filename, f.status, patch))
                        print(f"[FILE] âœ… LLM analysis completed for {f.filename}")

                print(f"[COMMIT] ğŸ¤– Sending commit summary to LLM...")
                meta = {
                    "repo": repo_full,
                    "sha": sha,
                    "title": title,
                    "author": author_name,
                    "author_login": author_login,
                    "author_email": author_email,
                    "date_kst": date_kst_str
                }
                commit_finding = summarize_commit(file_findings, meta)
                commits_all.append(commit_finding)
                my_commits.append(commit_finding)
                print(f"[COMMIT] âœ… Completed analysis for {sha[:7]}")
            
            print(f"[REPO] ğŸ“Š Found {len(my_commits)} of your commits in {repo_full}")
            
        except Exception as e:
            print(f"[REPO] âŒ Error processing {repo_full}: {str(e)}")
            print(f"[REPO] ğŸ”„ Continuing with next repository...")
            continue

    print(f"\n[SUMMARY] ğŸ“Š Analysis completed!")
    print(f"[SUMMARY] ğŸ“ˆ Total commits analyzed: {len(commits_all)}")
    print(f"[SUMMARY] ğŸ“ Generating report...")

    report = ReportModel(
        generated_at=dt.datetime.utcnow().strftime("%Y-%m-%d %H:%M:%S UTC"),
        model=OPENAI_MODEL,
        note_date_kst=note_date,
        repos=DEFAULT_REPOS,
        branch=BRANCH,
        author_filter={"login": MY_GITHUB_LOGIN, "email": MY_GITHUB_EMAIL},
        commits=commits_all
    )

    md_path = os.path.join(OUT_DIR, f"research_note_{note_date.replace('-','')}.md")
    json_path = os.path.join(OUT_DIR, f"research_note_{note_date.replace('-','')}.json")

    print(f"[OUTPUT] ğŸ“„ Writing markdown report to: {md_path}")
    with open(md_path, "w", encoding="utf-8") as f:
        f.write(render_md(report))
    
    print(f"[OUTPUT] ğŸ“„ Writing JSON report to: {json_path}")
    with open(json_path, "w", encoding="utf-8") as f:
        f.write(json.dumps(report.to_dict(), indent=2, ensure_ascii=False))

    print(f"\nâœ… ì—°êµ¬ë…¸íŠ¸ ìƒì„± ì™„ë£Œ!")
    print(f"ğŸ“ Markdown: {md_path}")
    print(f"ğŸ“ JSON: {json_path}")
    print(f"ğŸ“Š Total commits: {len(commits_all)}")

if __name__ == "__main__":
    main()
